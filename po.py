# -*- coding: utf-8 -*-
"""PO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ji-irsGxzwQmWbczh0Wb4ssDYiEhMkJC

# **SETTING THE ENVIRONMENT**
"""

import sys
import numpy
import pandas
import scipy
import shap
import xgboost
import explainerdashboard
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import cvxpy as cp
import google.generativeai as genai
import requests
import json
from explainerdashboard.dashboards import ExplainerDashboard
from explainerdashboard import RegressionExplainer
from explainerdashboard.dashboard_components import *
from dash import dcc, html, Input, Output, Dash, dash_table
from explainerdashboard.dashboard_components.overview_components import FeatureDescriptionsComponent
import os

# Your API Key should be set as an environment variable in a real deployment
# Example: GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
genai.configure(api_key="AIzaSyCwuYewoYb74C_QjwHe151rI6Jn47VCbKE")

"""# **LOADING DATA**"""


df = pd.read_excel("daily.xlsx")
df.head()

df['Date'] = pd.to_datetime(df['Date'], errors='coerce', utc=True)
df['Date'] = df['Date'].dt.tz_localize(None)
df['Date'] = df['Date'].dt.normalize()

price_df = df.pivot(index='Date', columns='Symbol', values='Close')
price_df.index = pd.to_datetime(price_df.index)
price_df_filled = price_df.ffill().bfill()

"""1) Calculating return"""

returns = price_df.pct_change().dropna(how='all')
returns_interpolated = returns.interpolate(method='linear', limit_direction='both')
returns_df = returns_interpolated.fillna(method='ffill').fillna(method='bfill')

"""2) Calculating Beta, with setting a benchmark"""

return_mean = returns_df.mean(axis=1)
return_mean.name = 'Benchmark'
aligned = returns_df.join(return_mean, how='inner')

def calculate_beta(asset_returns, benchmark):
    return asset_returns.cov(benchmark) / benchmark.var()

betas = aligned.drop(columns='Benchmark').apply(lambda x: calculate_beta(x, aligned['Benchmark']))

"""3) Calculating VAR and CVAR"""

alpha = 0.95
var_dict = {}
cvar_dict = {}
var_raw_dict = {}

for asset in returns_df.columns:
    returns = returns_df[asset].dropna()
    var_cutoff = np.percentile(returns, (1 - alpha) * 100)
    var_value = -var_cutoff if var_cutoff < 0 else 0
    var_raw_dict[asset] = var_cutoff
    tail_losses = returns[returns <= var_cutoff]
    cvar_value = -tail_losses.mean() if len(tail_losses) > 0 else 0
    var_dict[asset] = var_value
    cvar_dict[asset] = cvar_value

risk_metrics_df = pd.DataFrame({
    'VaR_95': pd.Series(var_dict),
    'CVaR_95': pd.Series(cvar_dict),
    'VaR_raw': pd.Series(var_raw_dict)
})

risk_metrics_df = risk_metrics_df.sort_values(by='CVaR_95', ascending=True)
risk_metrics_df = risk_metrics_df.round(6)
var_df = risk_metrics_df['VaR_95']
cvar_df = risk_metrics_df['CVaR_95']

"""4) Calculating Sharpe Ratio"""

risk_free_rate = 0.042
trading_days = 252
sharpe_ratios = {}
for asset in returns_df.columns:
    asset_returns = returns_df[asset].dropna()
    mean_daily_return = asset_returns.mean()
    annualized_return = mean_daily_return * trading_days
    annualized_volatility = asset_returns.std(axis=0) * np.sqrt(trading_days)
    if annualized_volatility != 0:
        sharpe = (annualized_return - risk_free_rate) / annualized_volatility
    else:
        sharpe = np.nan
    sharpe_ratios[asset] = sharpe

sharpe_series = pd.Series(sharpe_ratios, name='Sharpe_Ratio').sort_values(ascending=False)

"""5) Calculating Max Drawdown"""

high_df = df.pivot(index='Date', columns='Symbol', values='High')
low_df = df.pivot(index='Date', columns='Symbol', values='Low')
drawdown_close = price_df.div(price_df.cummax()) - 1
max_drawdown_close = drawdown_close.min()
peak_high = high_df.cummax()
drawdown_intraday = low_df / peak_high - 1
max_drawdown_intraday = drawdown_intraday.min()

"""6) Volatility and Annualized Volatility"""

volatility = returns_df.std()
annualized_volatility = returns_df.std(axis=0) * np.sqrt(252)

"""**COMBINING ALL THE FEATURES**"""

features_df = pd.concat([
    volatility.rename("Volatility"),
    annualized_volatility.rename("Annualized_Volatility"),
    betas.rename("Beta"),
    risk_metrics_df['VaR_95'].rename("VaR_95"),
    risk_metrics_df['CVaR_95'].rename("CVaR_95"),
    sharpe_series.rename("Sharpe_Ratio"),
    max_drawdown_close.rename("Max_Drawdown_Close"),
    max_drawdown_intraday.rename("Max_Drawdown_Intraday")
], axis=1)

features_df = features_df.dropna()
expected_returns_annual = returns_df.mean() * 252
features_df['Expected_Return'] = expected_returns_annual[features_df.index]
X = features_df.drop(columns='Expected_Return')
y = features_df['Expected_Return']

"""# **TRAINING THE MODEL AND COMPUTING SHAP VALUES**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)
predicted_returns = model.predict(X)
explainer = shap.Explainer(model, X)
shap_values = explainer(X)

"""# **Portoflio Optimization** based on model predicted returns"""

daily_cov_matrix = returns_df.cov()
cov_matrix = daily_cov_matrix * 252

def portfolio_optimization_with_entropy(predicted_returns, cov_matrix, lambda_entropy, risk_aversion=0.5):
    n_assets = len(predicted_returns)
    weights = cp.Variable(n_assets)
    expected_return = predicted_returns @ weights
    risk = cp.quad_form(weights, cov_matrix)
    entropy = cp.sum(cp.entr(weights + 1e-10))
    objective = cp.Maximize(expected_return - risk_aversion * risk + lambda_entropy * entropy)
    constraints = [cp.sum(weights) == 1, weights >= 0]
    problem = cp.Problem(objective, constraints)
    problem.solve(solver=cp.SCS)
    w = weights.value
    w = np.maximum(w, 0)
    w /= w.sum()
    return w

def effective_num_assets(weights):
    return 1 / np.sum(weights**2)

shap_values_per_asset = np.abs(shap_values.values).sum(axis=1)

def avg_weighted_shap(weights, shap_values_per_asset):
    return np.dot(weights, shap_values_per_asset)

combined_df = pd.DataFrame({
    'Asset': X.index,
    'Predicted_Return': predicted_returns,
    'SHAP_Sum': shap_values_per_asset
}).set_index('Asset')

combined_df['Combined_Score'] = combined_df['Predicted_Return'] + combined_df['SHAP_Sum']
combined_df_sorted = combined_df.sort_values(by='Combined_Score', ascending=False)
lambda_values = np.linspace(0, 1, 20)
results = []
for lam in lambda_values:
    weights = portfolio_optimization_with_entropy(predicted_returns, cov_matrix, lambda_entropy=lam)
    eff_num = effective_num_assets(weights)
    avg_shap = avg_weighted_shap(weights, shap_values_per_asset)
    exp_return = np.dot(predicted_returns, weights)
    risk = weights.T @ cov_matrix @ weights
    results.append({
        'lambda_entropy': lam,
        'eff_num_assets': eff_num,
        'avg_shap': avg_shap,
        'expected_return': exp_return,
        'risk': risk,
        'weights': weights,
    })

results_df = pd.DataFrame(results)
results_df['score'] = results_df['eff_num_assets'] * results_df['avg_shap']
best_idx = results_df['score'].idxmax()
best_lambda = results_df.loc[best_idx, 'lambda_entropy']
best_weights = results_df.loc[best_idx, 'weights']
portfolio_df = pd.DataFrame({
    'Asset': X.index,
    'Weight': best_weights
}).set_index('Asset').sort_values(by='Weight', ascending=False)

"""# **DASHBOARD**"""

symbol_to_name = df[['Symbol', 'Name']].drop_duplicates().set_index('Symbol')['Name'].to_dict()

class AssetBehaviorTab(ExplainerComponent):
    def __init__(self, explainer, X, returns_df, best_weights, symbol_to_name):
        super().__init__(explainer, title="Asset Behaviour")
        self.X = X
        self.returns_df = returns_df
        self.best_weights = best_weights
        self.symbol_to_name = symbol_to_name

    @property
    def name(self):
        return "Asset Behaviour"

    def layout(self):
        return html.Div([
            html.H3("Asset Behaviour:"),
            dcc.Dropdown(
                id='asset-dropdown',
                options=[
                    {'label': f"{self.symbol_to_name[symbol]} ({symbol})", 'value': symbol}
                    for symbol in self.X.index
                ],
                value=[self.X.index[0]],
                multi=True,
                style={'width': '60%'}
            ),
            dcc.Checklist(
                id='include-optimized-check',
                options=[{'label': 'Include SHAP-Optimized Portfolio', 'value': 'include'}],
                value=['include']
            ),
            dcc.Graph(id='asset-portfolio-graph')
        ])

    def register_callbacks(self, app):
        @app.callback(
            Output('asset-portfolio-graph', 'figure'),
            Input('asset-dropdown', 'value'),
            Input('include-optimized-check', 'value')
        )
        def update_graph(selected_assets, include_optimized):
            if not selected_assets:
                return go.Figure()
            if isinstance(selected_assets, str):
                selected_assets = [selected_assets]
            fig = go.Figure()
            colors = ['blue', 'black', 'green', 'purple', 'brown', 'pink', 'orange', 'yellow', 'cyan', 'magenta']
            for i, asset in enumerate(selected_assets):
                asset_returns = self.returns_df[asset]
                asset_cum_returns = (1 + asset_returns).cumprod()
                fig.add_trace(go.Scatter(
                    x=asset_cum_returns.index,
                    y=asset_cum_returns,
                    mode='lines',
                    name=f"{asset} Returns",
                    line=dict(color=colors[i % len(colors)], width=2)
                ))
            weights = np.zeros(len(self.X))
            for asset in selected_assets:
                idx = list(self.X.index).index(asset)
                weights[idx] = 1.0 / len(selected_assets)
            portfolio_returns = self.returns_df.dot(weights)
            portfolio_cum_returns = (1 + portfolio_returns).cumprod()
            fig.add_trace(go.Scatter(
                x=portfolio_cum_returns.index,
                y=portfolio_cum_returns,
                mode='lines',
                name="Portfolio (Equal Weights)",
                line=dict(color='red', width=2)
            ))
            if 'include' in include_optimized:
                shap_portfolio_returns = self.returns_df.dot(self.best_weights)
                shap_portfolio_cum_returns = (1 + shap_portfolio_returns).cumprod()
                fig.add_trace(go.Scatter(
                    x=shap_portfolio_cum_returns.index,
                    y=shap_portfolio_cum_returns,
                    mode='lines',
                    name="Portfolio (SHAP-Optimized)",
                    line=dict(color='teal', width=2)
                ))
            fig.update_layout(
                title="Selected Assets vs Portfolio Performance",
                xaxis_title="Date",
                yaxis_title="Cumulative Returns",
                template="plotly_white",
                legend_title="Legend"
            )
            return fig

class TopNPortfoliosTab(ExplainerComponent):
    def __init__(self, explainer, combined_df_sorted, best_weights, symbol_to_name):
        super().__init__(explainer, title=" Top Portfolios")
        self.combined_df_sorted = combined_df_sorted
        self.best_weights = best_weights
        self.symbol_to_name = symbol_to_name

    @property
    def name(self):
        return "Top Portfolios"

    def layout(self):
        max_assets = min(20, len(self.combined_df_sorted))
        return html.Div([
            html.H3("ðŸ“¦ Best Performing Portfolios:"),
            html.Label("Number of portfolios to display (N):"),
            dcc.Slider(
                id='num-portfolios-slider',
                min=1,
                max=10,
                step=1,
                value=3,
                marks={i: str(i) for i in range(1, 11)},
            ),
            html.Br(),
            html.Label("Number of assets per portfolio (n):"),
            dcc.Slider(
                id='assets-per-portfolio-slider',
                min=1,
                max=max_assets,
                step=1,
                value=5,
                marks={i: str(i) for i in range(1, max_assets+1)},
            ),
            html.Div(id='portfolio-display'),
            html.Br(),
            html.H4("SHAP-Optimized Portfolio:"),
            dash_table.DataTable(
                id='shap-optimized-table',
                columns=[{"name": "Asset", "id": "Asset"}, {"name": "Weight", "id": "Weight"}],
                style_table={'overflowX': 'auto'},
                style_cell={'textAlign': 'left', 'padding': '5px'},
                style_header={'backgroundColor': '#f2f2f2', 'fontWeight': 'bold'}
            ),
        ])

    def register_callbacks(self, app):
        @app.callback(
            Output('portfolio-display', 'children'),
            Output('shap-optimized-table', 'data'),
            Input('num-portfolios-slider', 'value'),
            Input('assets-per-portfolio-slider', 'value')
        )
        def update_portfolios(N, n):
            portfolio_tables = []
            for i in range(N):
                start_idx = i * n
                end_idx = start_idx + n
                if end_idx > len(self.combined_df_sorted):
                    break
                portfolio_df = self.combined_df_sorted.iloc[start_idx:end_idx].copy()
                portfolio_df = portfolio_df.reset_index()
                portfolio_df['Asset_Name'] = portfolio_df['Asset'].apply(
                    lambda sym: f"{sym} - {self.symbol_to_name.get(sym, 'Unknown')}"
                )
                cols = ['Asset_Name'] + [col for col in portfolio_df.columns if col != 'Asset' and col != 'Asset_Name']
                portfolio_tables.append(html.Div([
                    html.H5(f"ðŸ“ Portfolio {i + 1}"),
                    dash_table.DataTable(
                        columns=[{"name": "Asset", "id": "Asset_Name"}] +
                                [{"name": col, "id": col} for col in cols[1:]],
                        data=portfolio_df[cols].to_dict('records'),
                        style_table={'overflowX': 'auto'},
                        style_cell={'textAlign': 'left', 'padding': '5px'},
                        style_header={'backgroundColor': '#f2f2f2', 'fontWeight': 'bold'}
                    ),
                    html.Br()
                ]))
            shap_df = pd.DataFrame({
                "Asset": self.combined_df_sorted.index,
                "Weight": self.best_weights
            })
            shap_df = shap_df[shap_df["Weight"] > 0].copy()
            shap_df['Asset_Name'] = shap_df['Asset'].apply(
                lambda sym: f"{sym} - {self.symbol_to_name.get(sym, 'Unknown')}"
            )
            shap_df = shap_df.sort_values(by="Weight", ascending=False).reset_index(drop=True)
            return (portfolio_tables if portfolio_tables else html.Div("No portfolios to display."),
                    shap_df[['Asset_Name', 'Weight']].rename(columns={'Asset_Name':'Asset'}).to_dict('records'))

class GeminiInsightsTab(ExplainerComponent):
    def __init__(self, explainer):
        super().__init__(explainer, title="ðŸ§  More Information")
        self.unique_companies = df[['Name', 'Symbol']].drop_duplicates().sort_values(by='Name')

    def layout(self):
        return html.Div([
            html.H3("ðŸ§  More Information"),
            html.Label("Select Company:"),
            dcc.Dropdown(
                id='gemini-company-dropdown',
                options=[
                    {
                        'label': f"{row['Name']} ({row['Symbol']})",
                        'value': f"{row['Symbol']}|{row['Name']}"
                    }
                    for _, row in self.unique_companies.iterrows()
                ],
                value=f"{self.unique_companies['Symbol'].iloc[0]}|{self.unique_companies['Name'].iloc[0]}",
                style={'width': '60%'}
            ),
            html.Label("Select Direction:"),
            dcc.Dropdown(
                id='gemini-direction-dropdown',
                options=[
                    {'label': 'Increase', 'value': 'increase'},
                    {'label': 'Decrease', 'value': 'decrease'}
                ],
                value='increase',
                style={'width': '60%'}
            ),
            html.Label("Select Start Date:"),
            dcc.DatePickerSingle(
                id='gemini-start-date',
                date=str(df['Date'].min().date())
            ),
            html.Br(),
            html.Label("Select End Date:"),
            dcc.DatePickerSingle(
                id='gemini-end-date',
                date=str(df['Date'].max().date())
            ),
            html.Br(), html.Br(),
            html.Button('Generate Insight with Gemini', id='generate-gemini-btn', n_clicks=0),
            html.Br(), html.Br(),
            html.Div(id='sector-output'),
            html.Div(id='gemini-response', style={
                'whiteSpace': 'pre-line',
                'border': '1px solid #ccc',
                'padding': '10px',
                'minHeight': '100px',
                'backgroundColor': '#f9f9f9',
                'fontSize': '14px'
            })
        ])

    def register_callbacks(self, app):
        @app.callback(
            [Output('sector-output', 'children'),
             Output('gemini-response', 'children')],
            Input('generate-gemini-btn', 'n_clicks'),
            [Input('gemini-company-dropdown', 'value'),
             Input('gemini-direction-dropdown', 'value'),
             Input('gemini-start-date', 'date'),
             Input('gemini-end-date', 'date')],
            prevent_initial_call=True
        )
        def fetch_gemini_insight(n_clicks, company_value, direction, start_date, end_date):
            if not all([company_value, direction, start_date, end_date]):
                return "âš ï¸ Please fill all fields.", ""
            try:
                symbol, company_name = company_value.split('|')
            except Exception:
                return "âš ï¸ Invalid company selected.", ""
            company_row = df[(df['Name'] == company_name) & (df['Symbol'] == symbol)]
            sector = company_row['Sector'].iloc[0] if (not company_row.empty and 'Sector' in company_row.columns) else "Unknown"
            prompt = (
                f"As a financial analyst, explain in exactly 50 words or less why {company_name} "
                f"({symbol}) stock showed a {direction} from {start_date} to {end_date}. "
                f"Base your response on specific news reports, earnings announcements, "
                f"analyst reports, or company newsletters. Be concise and factual. "
                f"Do not generate images or videos, only text."
            )
            try:
                gemini_output = query_gemini(prompt)
                words = gemini_output.split()
                if len(words) > 50:
                    gemini_output = ' '.join(words[:50]) + "..."
            except Exception as e:
                gemini_output = f"Error fetching insight: {str(e)}"
            return f"ðŸ­ Sector: {sector}", gemini_output

def query_gemini(prompt):
    try:
        API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyCwuYewoYb74C_QjwHe151rI6Jn47VCbKE")
        MODEL_NAME = "gemini-1.5-flash"
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"
        headers = {
            'Content-Type': 'application/json',
        }
        payload = {
            "contents": [
                {
                    "parts": [
                        {
                            "text": f"{prompt} Limit your response to exactly 50 words or less. Focus on specific news, earnings, or company announcements."
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.4,
                "topK": 32,
                "topP": 1,
                "maxOutputTokens": 100,
                "stopSequences": []
            }
        }
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text']
                words = content.split()
                if len(words) > 70:
                    content = ' '.join(words[:70]) + "..."
                return content
            else:
                return "No response generated from Gemini."
        else:
            error_detail = response.json() if response.content else {"error": "Unknown error"}
            return f"âŒ Error from Gemini API: {response.status_code} - {json.dumps(error_detail, indent=2)}"
    except Exception as e:
        return f"âŒ Exception occurred: {str(e)}"

feature_descriptions = {
    'Sharpe_Ratio':('It measures how much return the asset will give per unit of risk.'
    'Sharpe Ratio increases â†’ Better risk-adjusted return â†’ Increase in return per unit of risk'),
    'Volatility': ('It measures how much the return of the asset varies over time.'
    'Volatility increases â†’ More fluctuations â†’ More risk'),
    'VaR_95':('A risk measure that tells us how much we could lose over a given time period.'
    'VaR increases â†’ Risk of loss increases'),
    'CVaR_95': 'A risk measure that tells us the average loss one would experience beyond the VaR threshold.',
    'Annualized_Volatility': "It tells you how much a stock's price is likely to fluctuate over a one-year period.",
    'Beta': (
        "A measure of how much an asset's returns tends to move relative to a benchmark."
        "If beta > 1: Asset is more volatile than the market."
        "If beta = 1: Asset moves in sync with the market."
        "If beta < 1: Asset is less volatile than the market."
    ),
    'Max_Drawdown_Intraday': 'It measures the largest historical loss from the highest peak to the lowest intraday price.',
    'Max_Drawdown_Close': (
        "It measures the largest historical loss an asset has experienced using closing prices."
        "Max drawdown increases â†’ Risk increases â†’ Asset can lose a large portion of its value during bad days"
    )
}

explainer = RegressionExplainer(model, X, y, shap='tree', descriptions=feature_descriptions)
feature_descriptions_component = FeatureDescriptionsComponent(explainer, title="Feature Descriptions")
asset_tab = AssetBehaviorTab(explainer, X, returns_df, best_weights, symbol_to_name)
topn_tab = TopNPortfoliosTab(explainer, combined_df_sorted, best_weights, symbol_to_name)
gemini_tab = GeminiInsightsTab(explainer)

db = ExplainerDashboard(
    explainer,
    title="ðŸ“ˆ Portfolio Explainer Dashboard",
    tabs=[
        "model_summary",
        feature_descriptions_component,
        "shap_dependence",
        "whatif",
        "contributions",
        asset_tab,
        topn_tab,
        gemini_tab
    ],
    hide_sidebar=True,
    width=1200,
    dark_mode=False
)

# Start the dashboard on the port provided by the environment
# The default port for Cloud Run is 8080
if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    db.run(port=port, host='0.0.0.0', server=None)